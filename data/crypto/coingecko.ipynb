{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "b25a0071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/clare/miniconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: pycoingecko in /home/clare/miniconda3/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/clare/miniconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/clare/miniconda3/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/clare/miniconda3/lib/python3.9/site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: requests in /home/clare/miniconda3/lib/python3.9/site-packages (from pycoingecko) (2.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/clare/miniconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/clare/miniconda3/lib/python3.9/site-packages (from requests->pycoingecko) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/clare/miniconda3/lib/python3.9/site-packages (from requests->pycoingecko) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/clare/miniconda3/lib/python3.9/site-packages (from requests->pycoingecko) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/clare/miniconda3/lib/python3.9/site-packages (from requests->pycoingecko) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install pandas pycoingecko \n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import json\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "cg = CoinGeckoAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "799d5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dic={\n",
    "    \"id\": ['1435120030245662722','1354488469091975168','1433401141237256193','1392602041025843203','1356310219215699968','1340590280848908288'],\n",
    "    \"coin\": ['bitcoin','bitcoin','bitcoin','bitcoin','bitcoin','dogecoin'],\n",
    "    \"currency\": ['usd','usd','usd','usd','usd','usd'],\n",
    "    \"creator\": ['Nayib Bukele','Mayor Francis Suarez','Michael Saylor','Elon Musk','Willy Woo','Elon Musk'],\n",
    "}\n",
    "tweet_df = pd.DataFrame(tweet_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "8f25781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweet_date = \"2018-07-18 01:58:00\"\n",
    "#coin='bitcoin'\n",
    "#currency='usd'\n",
    "#date_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "#1 day from current time will produce 5min interval\n",
    "#1-90 hourly interval\n",
    "#above 90 days is daily\n",
    "#number_of_days = 45\n",
    "#number_of_hours = 0\n",
    "#tweet_datetime = pd.to_datetime(tweet_date,format=date_format)\n",
    "#tweet_datetime= pd.to_datetime(\"2021-09-07T05:57:00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "9b0409f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set your enviornment variables in your terminal run the following line:\n",
    "#export 'BEARER_TOKEN'='AAAAAAAAAAAAAAAAAAAAACGakwEAAAAA9AmAwPyPkNa%2BDAFSRniHzrezwiY%3Dz2T8TZvftexbR58cnUQ6wLip4ra9SfafHlJaUOmLn8lv5Fah5Z'\n",
    "bearer_token ='AAAAAAAAAAAAAAAAAAAAACGakwEAAAAA9AmAwPyPkNa%2BDAFSRniHzrezwiY%3Dz2T8TZvftexbR58cnUQ6wLip4ra9SfafHlJaUOmLn8lv5Fah5Z'\n",
    "#bearer_token = os.environ.get(\"AAAAAAAAAAAAAAAAAAAAACGakwEAAAAA9AmAwPyPkNa%2BDAFSRniHzrezwiY%3Dz2T8TZvftexbR58cnUQ6wLip4ra9SfafHlJaUOmLn8lv5Fah5Z\")\n",
    "\n",
    "\n",
    "def create_url(twt_id):\n",
    "    tweet_fields = \"tweet.fields=author_id,created_at,text\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    ids = \"ids=\" + twt_id\n",
    "    # You can adjust ids to include a single Tweets.\n",
    "    # Or you can add to up to 100 comma-separated IDs\n",
    "    url = \"https://api.twitter.com/2/tweets?{}&{}\".format(ids, tweet_fields)\n",
    "    return url\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2TweetLookupPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url):\n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_tweet_timestamp(twt_id):\n",
    "    url = create_url(twt_id)\n",
    "    json_response = connect_to_endpoint(url)\n",
    "    #return timestamp with timezone removed\n",
    "    return pd.to_datetime(json_response['data'][0]['created_at'][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "98d18aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "tweet_df['timestamp']=tweet_df['id'].map(lambda ids: get_tweet_timestamp(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "bb2bc4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv(\"./tweets.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "b64bfee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('./tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "73bcdc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['timestamp']=tweets['timestamp'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "41800cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prices_df(twt_dt,coin,currency,number_of_days=45,number_of_hours=0):\n",
    "    tweet_from_timestamp = (twt_dt - dt.timedelta(days=number_of_days,hours=number_of_hours)).timestamp()\n",
    "    tweet_to_timestamp = (twt_dt + dt.timedelta(days=number_of_days,hours=number_of_hours)).timestamp()\n",
    "    coin_gecko_data = cg.get_coin_market_chart_range_by_id(id=coin,\n",
    "                                                vs_currency=currency,\n",
    "                                                from_timestamp=tweet_from_timestamp,\n",
    "                                                to_timestamp=tweet_to_timestamp)\n",
    "     \n",
    "    return parse_coin_data(coin_gecko_data)\n",
    "def prepend_past_prices(df,coin,currency,number_of_days=45,n=1):\n",
    "    copy_df = df.copy()\n",
    "    for i in range(n):\n",
    "        first_date = list(copy_df['date'])[0] \n",
    "        to_timestamp = (first_date - dt.timedelta(hours=0.5)).timestamp()\n",
    "        from_timestamp = (first_date - dt.timedelta(days=(number_of_days * 2))).timestamp()\n",
    "        coin_gecko_data = cg.get_coin_market_chart_range_by_id(id=coin,\n",
    "                                                               vs_currency=currency,\n",
    "                                                               from_timestamp=from_timestamp,\n",
    "                                                               to_timestamp=to_timestamp)\n",
    "        new_df = parse_coin_data(coin_gecko_data)\n",
    "        copy_df = pd.concat([new_df,copy_df]).reset_index(drop=True)\n",
    "    return copy_df\n",
    "def append_future_prices(df,coin,currency,number_of_days=45,n=1):\n",
    "    copy_df = df.copy()\n",
    "    for i in range(n):\n",
    "        last_date = list(copy_df['date'])[-1] \n",
    "        from_timestamp = (last_date + dt.timedelta(hours=0.5)).timestamp()\n",
    "        to_timestamp = (last_date + dt.timedelta(days=(number_of_days*2))).timestamp()\n",
    "        coin_gecko_data = cg.get_coin_market_chart_range_by_id(id=coin,\n",
    "                                                               vs_currency=currency,\n",
    "                                                               from_timestamp=from_timestamp,\n",
    "                                                               to_timestamp=to_timestamp)\n",
    "        new_df = parse_coin_data(coin_gecko_data)\n",
    "        copy_df = pd.concat([copy_df,new_df]).reset_index(drop=True)\n",
    "    return copy_df\n",
    "def get_large_intervals(twt_dt,coin,currency,number_of_days=45,n=1):\n",
    "    original_df = generate_prices_df(twt_dt,coin,currency,number_of_days)\n",
    "    past = prepend_past_prices(original_df,coin,currency,number_of_days,n)\n",
    "    return append_future_prices(past,coin,currency,number_of_days,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "6593e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_coin_data(coin_data):\n",
    "    parsed_data = {}\n",
    "    timestamps=list(map(lambda x:x[0],coin_data['prices']))\n",
    "    for key in coin_data.keys():\n",
    "        parsed_data[key] = list(map(lambda x:x[1], coin_data[key]))\n",
    "    parsed_data['timestamps']=timestamps\n",
    "    df=pd.DataFrame(parsed_data)\n",
    "    df['date']=pd.to_datetime(df['timestamps'],origin='unix',unit='ms')\n",
    "    return df\n",
    "def produce_intervals_for_each(tweets_df,size=1,directory=\"./prices/\"):\n",
    "    for _, row in tqdm (tweets_df.iterrows(), desc=\"Creating intervals...\") :\n",
    "        coin = row['coin']\n",
    "        currency = row['currency']\n",
    "        creator = row['creator']\n",
    "        timestamp = row['timestamp']\n",
    "        row_df = get_large_intervals(timestamp,coin,currency,n=size)\n",
    "        filepath = directory + (creator.lower() + \" \" + coin + \" vs \" + currency + \" \" + str(timestamp) + \" \" + \".csv\").replace(\" \", \"_\")\n",
    "        row_df.to_csv(filepath,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "6e1e9851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating intervals...: 6it [03:30, 35.11s/it]\n"
     ]
    }
   ],
   "source": [
    "produce_intervals_for_each(tweets,size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "ba093ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating intervals...: 1it [00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "last =tweets[tweets['coin']=='dogecoin']\n",
    "produce_intervals_for_each(last,size=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
